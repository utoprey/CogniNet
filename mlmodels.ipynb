{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "031cc954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import os\n",
    "import itertools \n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f005993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed =1380\n",
    "np.random.seed(seed)\n",
    "random.seed(seed) \n",
    "os.environ['PYTHONHASHSEED']=str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3bca760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cobre_splits_path =\"cobre_splits (5).json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b7f3577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_path =cobre_raw_data =\"C:/Users/ZenBook/Desktop/shiza/cobre/aal/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e75c58e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cobre_splits_path, 'r') as f:\n",
    "    data_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8f3ef95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(cobre_data):\n",
    "    del cobre_data['Unnamed: 0']\n",
    "    data_dict ={}\n",
    "    for i,column in enumerate(cobre_data.columns):\n",
    "        for j in range(0,i):\n",
    "            data_dict[(column, cobre_data.columns[j])] =cobre_data.iloc[i,j]\n",
    "    return data_dict        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e1c5dda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00000368.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00000456.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00000541.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00000838.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00000909.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00001181.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00001243.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00001251.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00001452.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00002480.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00003150.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00004087.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00004507.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00006754.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00007409.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00009280.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00010150.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00010684.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00011265.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00011725.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00012995.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00013140.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00013363.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00013816.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00014120.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00014175.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00014225.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00014522.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00014590.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00014607.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00014636.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00014719.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00014804.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00014830.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00014898.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00015201.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00015518.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00015648.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00015759.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00015826.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00016197.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00016720.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00016723.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00017147.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00017294.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00018129.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00018317.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00018403.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00018553.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00018979.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00019293.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00019349.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00019750.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00019888.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00020414.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00020416.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00020602.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00020787.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00020805.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00020895.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00020968.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00020984.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00021058.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00021072.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00021081.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00021085.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00021591.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00021598.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00022400.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00022490.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00022500.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00022509.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00022592.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00022653.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00022687.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00022727.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00022729.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00022773.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00022810.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00022835.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00022837.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00022915.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00023095.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00023120.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00023131.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00023158.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00023243.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00023246.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00023330.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00023337.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00023590.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00023730.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00023750.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00023800.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00023848.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00023866.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00024160.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00024198.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00024228.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00024301.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00024372.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00024446.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00024535.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00024546.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00024568.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00024663.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00024684.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00024932.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00024953.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00024955.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00024959.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00025969.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00026907.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00026945.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00027391.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00027410.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00027487.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00027537.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00027755.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00027787.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00027969.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00028052.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00028189.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00028303.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00028402.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00028404.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00028405.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00028408.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00028409.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00028805.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00028806.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00029226.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00029452.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00029486.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00031271.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00031478.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00031597.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00031764.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00033214.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00035003.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00035485.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00035751.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00035836.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00035859.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00036049.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00036555.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00036844.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00036897.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00036916.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00037007.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00037034.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00037224.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00037238.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00037318.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00037495.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00037564.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00037619.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00037649.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00037665.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00037854.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00038172.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00038441.csv\n",
      "(116, 117)\n",
      "C:\\Users\\ZenBook\\Desktop\\shiza\\cobre\\aal\\sub-A00038624.csv\n",
      "(116, 117)\n"
     ]
    }
   ],
   "source": [
    "data =[]\n",
    "for path in Path(subjects_path).iterdir():\n",
    "    if \".csv\" in str(path) and  \"embed\" not in str(path):\n",
    "        print(path)\n",
    "        cobre_data =pd.read_csv(path)\n",
    "        print(cobre_data.shape)\n",
    "        dict_data =get_data(cobre_data)\n",
    "        dict_data[\"id\"] =path.stem\n",
    "        data.append(dict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0706a774",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =pd.DataFrame.from_records(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2284f80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['id'] = dataset['id'].apply(lambda x : x[4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "550d6620",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data =pd.read_table(\"meta_data.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3b37fa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data =meta_data[['Subjectid', 'Dx']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c012ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data=meta_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c42e4b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =dataset.merge(meta_data, left_on =\"id\", right_on=\"Subjectid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2b8e8521",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =dataset.loc[dataset.Dx.isin([\"Schizophrenia_Strict\", \"No_Known_Disorder\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "052a04ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"cobre_multimodal_only_fmri.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8cdccfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "----------------\n",
      "----------------\n",
      "----------------\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "for i, elem in enumerate(data_json['train']):\n",
    "    train_ids =elem['train']\n",
    "    valid_ids =elem['valid']\n",
    "    \n",
    "    print(\"----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f75db425",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8b7aef47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(Precentral_R, Precentral_L)</th>\n",
       "      <th>(Frontal_Sup_L, Precentral_L)</th>\n",
       "      <th>(Frontal_Sup_L, Precentral_R)</th>\n",
       "      <th>(Frontal_Sup_R, Precentral_L)</th>\n",
       "      <th>(Frontal_Sup_R, Precentral_R)</th>\n",
       "      <th>(Frontal_Sup_R, Frontal_Sup_L)</th>\n",
       "      <th>(Frontal_Sup_Orb_L, Precentral_L)</th>\n",
       "      <th>(Frontal_Sup_Orb_L, Precentral_R)</th>\n",
       "      <th>(Frontal_Sup_Orb_L, Frontal_Sup_L)</th>\n",
       "      <th>(Frontal_Sup_Orb_L, Frontal_Sup_R)</th>\n",
       "      <th>...</th>\n",
       "      <th>(Vermis_10, Cerebelum_10_R)</th>\n",
       "      <th>(Vermis_10, Vermis_1_2)</th>\n",
       "      <th>(Vermis_10, Vermis_3)</th>\n",
       "      <th>(Vermis_10, Vermis_4_5)</th>\n",
       "      <th>(Vermis_10, Vermis_6)</th>\n",
       "      <th>(Vermis_10, Vermis_7)</th>\n",
       "      <th>(Vermis_10, Vermis_8)</th>\n",
       "      <th>(Vermis_10, Vermis_9)</th>\n",
       "      <th>Subjectid</th>\n",
       "      <th>Dx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.590307</td>\n",
       "      <td>0.215914</td>\n",
       "      <td>0.304414</td>\n",
       "      <td>0.116425</td>\n",
       "      <td>0.165778</td>\n",
       "      <td>0.255798</td>\n",
       "      <td>0.031173</td>\n",
       "      <td>-0.113507</td>\n",
       "      <td>0.038880</td>\n",
       "      <td>0.170122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258102</td>\n",
       "      <td>0.078604</td>\n",
       "      <td>-0.023349</td>\n",
       "      <td>-0.069403</td>\n",
       "      <td>-0.019248</td>\n",
       "      <td>0.273587</td>\n",
       "      <td>0.323913</td>\n",
       "      <td>0.156899</td>\n",
       "      <td>A00000368</td>\n",
       "      <td>Schizophrenia_Strict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.600053</td>\n",
       "      <td>0.450454</td>\n",
       "      <td>0.407950</td>\n",
       "      <td>0.554324</td>\n",
       "      <td>0.457576</td>\n",
       "      <td>0.747958</td>\n",
       "      <td>0.101570</td>\n",
       "      <td>-0.024283</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.244049</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015206</td>\n",
       "      <td>0.073420</td>\n",
       "      <td>0.150168</td>\n",
       "      <td>-0.086901</td>\n",
       "      <td>0.118768</td>\n",
       "      <td>0.432538</td>\n",
       "      <td>0.563580</td>\n",
       "      <td>0.360348</td>\n",
       "      <td>A00000456</td>\n",
       "      <td>Schizophrenia_Strict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.527959</td>\n",
       "      <td>0.504611</td>\n",
       "      <td>0.580334</td>\n",
       "      <td>0.447950</td>\n",
       "      <td>0.648701</td>\n",
       "      <td>0.642671</td>\n",
       "      <td>-0.337435</td>\n",
       "      <td>-0.127757</td>\n",
       "      <td>0.064094</td>\n",
       "      <td>-0.071411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186776</td>\n",
       "      <td>0.361453</td>\n",
       "      <td>-0.053617</td>\n",
       "      <td>0.068982</td>\n",
       "      <td>0.292669</td>\n",
       "      <td>0.534355</td>\n",
       "      <td>0.470277</td>\n",
       "      <td>0.570458</td>\n",
       "      <td>A00000541</td>\n",
       "      <td>Schizophrenia_Strict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.640427</td>\n",
       "      <td>0.425068</td>\n",
       "      <td>0.470462</td>\n",
       "      <td>0.313035</td>\n",
       "      <td>0.265838</td>\n",
       "      <td>0.615625</td>\n",
       "      <td>-0.134986</td>\n",
       "      <td>-0.242692</td>\n",
       "      <td>-0.040470</td>\n",
       "      <td>0.093006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012403</td>\n",
       "      <td>-0.201170</td>\n",
       "      <td>0.272472</td>\n",
       "      <td>-0.022364</td>\n",
       "      <td>-0.157833</td>\n",
       "      <td>-0.103954</td>\n",
       "      <td>0.078484</td>\n",
       "      <td>0.040241</td>\n",
       "      <td>A00000838</td>\n",
       "      <td>Schizophrenia_Strict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.427308</td>\n",
       "      <td>0.239172</td>\n",
       "      <td>0.101873</td>\n",
       "      <td>0.266489</td>\n",
       "      <td>0.325015</td>\n",
       "      <td>0.580501</td>\n",
       "      <td>0.027387</td>\n",
       "      <td>-0.153969</td>\n",
       "      <td>0.092569</td>\n",
       "      <td>-0.007205</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081796</td>\n",
       "      <td>0.289600</td>\n",
       "      <td>0.185260</td>\n",
       "      <td>0.197285</td>\n",
       "      <td>0.071489</td>\n",
       "      <td>0.085987</td>\n",
       "      <td>0.124079</td>\n",
       "      <td>0.504530</td>\n",
       "      <td>A00000909</td>\n",
       "      <td>Schizophrenia_Strict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.787778</td>\n",
       "      <td>0.418824</td>\n",
       "      <td>0.420073</td>\n",
       "      <td>0.536880</td>\n",
       "      <td>0.531874</td>\n",
       "      <td>0.776564</td>\n",
       "      <td>0.222002</td>\n",
       "      <td>0.235727</td>\n",
       "      <td>-0.130599</td>\n",
       "      <td>0.042551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.287224</td>\n",
       "      <td>0.044076</td>\n",
       "      <td>-0.042164</td>\n",
       "      <td>-0.138347</td>\n",
       "      <td>0.116347</td>\n",
       "      <td>-0.128351</td>\n",
       "      <td>-0.010187</td>\n",
       "      <td>0.564968</td>\n",
       "      <td>A00037649</td>\n",
       "      <td>Schizophrenia_Strict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.837095</td>\n",
       "      <td>0.699350</td>\n",
       "      <td>0.567253</td>\n",
       "      <td>0.628090</td>\n",
       "      <td>0.484317</td>\n",
       "      <td>0.816644</td>\n",
       "      <td>0.515332</td>\n",
       "      <td>0.440825</td>\n",
       "      <td>0.597178</td>\n",
       "      <td>0.574797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013771</td>\n",
       "      <td>-0.297782</td>\n",
       "      <td>0.018670</td>\n",
       "      <td>-0.199247</td>\n",
       "      <td>0.221397</td>\n",
       "      <td>-0.145123</td>\n",
       "      <td>0.218707</td>\n",
       "      <td>-0.338076</td>\n",
       "      <td>A00037665</td>\n",
       "      <td>No_Known_Disorder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.626127</td>\n",
       "      <td>0.367332</td>\n",
       "      <td>0.178448</td>\n",
       "      <td>0.252641</td>\n",
       "      <td>0.384334</td>\n",
       "      <td>0.654329</td>\n",
       "      <td>0.114585</td>\n",
       "      <td>0.223127</td>\n",
       "      <td>-0.013945</td>\n",
       "      <td>0.164300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286602</td>\n",
       "      <td>0.362241</td>\n",
       "      <td>0.263336</td>\n",
       "      <td>0.268425</td>\n",
       "      <td>0.312150</td>\n",
       "      <td>0.147089</td>\n",
       "      <td>0.466238</td>\n",
       "      <td>0.586675</td>\n",
       "      <td>A00037854</td>\n",
       "      <td>Schizophrenia_Strict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.457744</td>\n",
       "      <td>0.486875</td>\n",
       "      <td>0.204815</td>\n",
       "      <td>0.321213</td>\n",
       "      <td>0.284081</td>\n",
       "      <td>0.572457</td>\n",
       "      <td>-0.062898</td>\n",
       "      <td>-0.092247</td>\n",
       "      <td>-0.064799</td>\n",
       "      <td>-0.135443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507622</td>\n",
       "      <td>0.348055</td>\n",
       "      <td>0.089759</td>\n",
       "      <td>-0.062223</td>\n",
       "      <td>0.229889</td>\n",
       "      <td>0.489779</td>\n",
       "      <td>0.626306</td>\n",
       "      <td>0.491610</td>\n",
       "      <td>A00038441</td>\n",
       "      <td>Schizophrenia_Strict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.557446</td>\n",
       "      <td>0.129209</td>\n",
       "      <td>0.156019</td>\n",
       "      <td>0.203429</td>\n",
       "      <td>0.227152</td>\n",
       "      <td>0.392719</td>\n",
       "      <td>-0.016883</td>\n",
       "      <td>0.001975</td>\n",
       "      <td>0.058075</td>\n",
       "      <td>0.134549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073617</td>\n",
       "      <td>0.149316</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.215443</td>\n",
       "      <td>0.254942</td>\n",
       "      <td>0.365357</td>\n",
       "      <td>0.477884</td>\n",
       "      <td>0.403335</td>\n",
       "      <td>A00038624</td>\n",
       "      <td>Schizophrenia_Strict</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows Ã— 6672 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     (Precentral_R, Precentral_L)  (Frontal_Sup_L, Precentral_L)  \\\n",
       "0                        0.590307                       0.215914   \n",
       "1                        0.600053                       0.450454   \n",
       "2                        0.527959                       0.504611   \n",
       "3                        0.640427                       0.425068   \n",
       "4                        0.427308                       0.239172   \n",
       "..                            ...                            ...   \n",
       "157                      0.787778                       0.418824   \n",
       "158                      0.837095                       0.699350   \n",
       "159                      0.626127                       0.367332   \n",
       "161                      0.457744                       0.486875   \n",
       "162                      0.557446                       0.129209   \n",
       "\n",
       "     (Frontal_Sup_L, Precentral_R)  (Frontal_Sup_R, Precentral_L)  \\\n",
       "0                         0.304414                       0.116425   \n",
       "1                         0.407950                       0.554324   \n",
       "2                         0.580334                       0.447950   \n",
       "3                         0.470462                       0.313035   \n",
       "4                         0.101873                       0.266489   \n",
       "..                             ...                            ...   \n",
       "157                       0.420073                       0.536880   \n",
       "158                       0.567253                       0.628090   \n",
       "159                       0.178448                       0.252641   \n",
       "161                       0.204815                       0.321213   \n",
       "162                       0.156019                       0.203429   \n",
       "\n",
       "     (Frontal_Sup_R, Precentral_R)  (Frontal_Sup_R, Frontal_Sup_L)  \\\n",
       "0                         0.165778                        0.255798   \n",
       "1                         0.457576                        0.747958   \n",
       "2                         0.648701                        0.642671   \n",
       "3                         0.265838                        0.615625   \n",
       "4                         0.325015                        0.580501   \n",
       "..                             ...                             ...   \n",
       "157                       0.531874                        0.776564   \n",
       "158                       0.484317                        0.816644   \n",
       "159                       0.384334                        0.654329   \n",
       "161                       0.284081                        0.572457   \n",
       "162                       0.227152                        0.392719   \n",
       "\n",
       "     (Frontal_Sup_Orb_L, Precentral_L)  (Frontal_Sup_Orb_L, Precentral_R)  \\\n",
       "0                             0.031173                          -0.113507   \n",
       "1                             0.101570                          -0.024283   \n",
       "2                            -0.337435                          -0.127757   \n",
       "3                            -0.134986                          -0.242692   \n",
       "4                             0.027387                          -0.153969   \n",
       "..                                 ...                                ...   \n",
       "157                           0.222002                           0.235727   \n",
       "158                           0.515332                           0.440825   \n",
       "159                           0.114585                           0.223127   \n",
       "161                          -0.062898                          -0.092247   \n",
       "162                          -0.016883                           0.001975   \n",
       "\n",
       "     (Frontal_Sup_Orb_L, Frontal_Sup_L)  (Frontal_Sup_Orb_L, Frontal_Sup_R)  \\\n",
       "0                              0.038880                            0.170122   \n",
       "1                              0.218750                            0.244049   \n",
       "2                              0.064094                           -0.071411   \n",
       "3                             -0.040470                            0.093006   \n",
       "4                              0.092569                           -0.007205   \n",
       "..                                  ...                                 ...   \n",
       "157                           -0.130599                            0.042551   \n",
       "158                            0.597178                            0.574797   \n",
       "159                           -0.013945                            0.164300   \n",
       "161                           -0.064799                           -0.135443   \n",
       "162                            0.058075                            0.134549   \n",
       "\n",
       "     ...  (Vermis_10, Cerebelum_10_R)  (Vermis_10, Vermis_1_2)  \\\n",
       "0    ...                     0.258102                 0.078604   \n",
       "1    ...                    -0.015206                 0.073420   \n",
       "2    ...                     0.186776                 0.361453   \n",
       "3    ...                     0.012403                -0.201170   \n",
       "4    ...                    -0.081796                 0.289600   \n",
       "..   ...                          ...                      ...   \n",
       "157  ...                     0.287224                 0.044076   \n",
       "158  ...                     0.013771                -0.297782   \n",
       "159  ...                     0.286602                 0.362241   \n",
       "161  ...                     0.507622                 0.348055   \n",
       "162  ...                     0.073617                 0.149316   \n",
       "\n",
       "     (Vermis_10, Vermis_3)  (Vermis_10, Vermis_4_5)  (Vermis_10, Vermis_6)  \\\n",
       "0                -0.023349                -0.069403              -0.019248   \n",
       "1                 0.150168                -0.086901               0.118768   \n",
       "2                -0.053617                 0.068982               0.292669   \n",
       "3                 0.272472                -0.022364              -0.157833   \n",
       "4                 0.185260                 0.197285               0.071489   \n",
       "..                     ...                      ...                    ...   \n",
       "157              -0.042164                -0.138347               0.116347   \n",
       "158               0.018670                -0.199247               0.221397   \n",
       "159               0.263336                 0.268425               0.312150   \n",
       "161               0.089759                -0.062223               0.229889   \n",
       "162               0.353535                 0.215443               0.254942   \n",
       "\n",
       "     (Vermis_10, Vermis_7)  (Vermis_10, Vermis_8)  (Vermis_10, Vermis_9)  \\\n",
       "0                 0.273587               0.323913               0.156899   \n",
       "1                 0.432538               0.563580               0.360348   \n",
       "2                 0.534355               0.470277               0.570458   \n",
       "3                -0.103954               0.078484               0.040241   \n",
       "4                 0.085987               0.124079               0.504530   \n",
       "..                     ...                    ...                    ...   \n",
       "157              -0.128351              -0.010187               0.564968   \n",
       "158              -0.145123               0.218707              -0.338076   \n",
       "159               0.147089               0.466238               0.586675   \n",
       "161               0.489779               0.626306               0.491610   \n",
       "162               0.365357               0.477884               0.403335   \n",
       "\n",
       "     Subjectid                    Dx  \n",
       "0    A00000368  Schizophrenia_Strict  \n",
       "1    A00000456  Schizophrenia_Strict  \n",
       "2    A00000541  Schizophrenia_Strict  \n",
       "3    A00000838  Schizophrenia_Strict  \n",
       "4    A00000909  Schizophrenia_Strict  \n",
       "..         ...                   ...  \n",
       "157  A00037649  Schizophrenia_Strict  \n",
       "158  A00037665     No_Known_Disorder  \n",
       "159  A00037854  Schizophrenia_Strict  \n",
       "161  A00038441  Schizophrenia_Strict  \n",
       "162  A00038624  Schizophrenia_Strict  \n",
       "\n",
       "[152 rows x 6672 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1fbde92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Dx']=dataset['Dx'].map({'Schizophrenia_Strict':1, \"No_Known_Disorder\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c479d652",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'class_weight': [\"balanced\", None],\n",
    "                       'penalty': ['l1', 'l2'],\n",
    "                       'C': [0.01, 0.1, 1, 3, 10],\n",
    "                       'solver': ['liblinear'],\n",
    "                       'random_state': [seed]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5eaa3868",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys, values = zip(*hyperparameters.items())\n",
    "hyperparameter_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e8b660b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splits_data(dataset, split):\n",
    "    train_ids, valid_ids =split['train'],split['valid']\n",
    "\n",
    "    train_data =dataset.loc[dataset.Subjectid.isin(train_ids)]\n",
    "    val_data =dataset.loc[dataset.Subjectid.isin(valid_ids)]\n",
    "    X_train, y_train =train_data.iloc[:,:-2], train_data.iloc[:,-1]\n",
    "    X_val, y_val =val_data.iloc[:,:-2], val_data.iloc[:,-1]\n",
    "    return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2fcb426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val =splits_data(dataset, data_json['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6022d753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(Precentral_R, Precentral_L)</th>\n",
       "      <th>(Frontal_Sup_L, Precentral_L)</th>\n",
       "      <th>(Frontal_Sup_L, Precentral_R)</th>\n",
       "      <th>(Frontal_Sup_R, Precentral_L)</th>\n",
       "      <th>(Frontal_Sup_R, Precentral_R)</th>\n",
       "      <th>(Frontal_Sup_R, Frontal_Sup_L)</th>\n",
       "      <th>(Frontal_Sup_Orb_L, Precentral_L)</th>\n",
       "      <th>(Frontal_Sup_Orb_L, Precentral_R)</th>\n",
       "      <th>(Frontal_Sup_Orb_L, Frontal_Sup_L)</th>\n",
       "      <th>(Frontal_Sup_Orb_L, Frontal_Sup_R)</th>\n",
       "      <th>...</th>\n",
       "      <th>(Vermis_10, Cerebelum_9_R)</th>\n",
       "      <th>(Vermis_10, Cerebelum_10_L)</th>\n",
       "      <th>(Vermis_10, Cerebelum_10_R)</th>\n",
       "      <th>(Vermis_10, Vermis_1_2)</th>\n",
       "      <th>(Vermis_10, Vermis_3)</th>\n",
       "      <th>(Vermis_10, Vermis_4_5)</th>\n",
       "      <th>(Vermis_10, Vermis_6)</th>\n",
       "      <th>(Vermis_10, Vermis_7)</th>\n",
       "      <th>(Vermis_10, Vermis_8)</th>\n",
       "      <th>(Vermis_10, Vermis_9)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.590307</td>\n",
       "      <td>0.215914</td>\n",
       "      <td>0.304414</td>\n",
       "      <td>0.116425</td>\n",
       "      <td>0.165778</td>\n",
       "      <td>0.255798</td>\n",
       "      <td>0.031173</td>\n",
       "      <td>-0.113507</td>\n",
       "      <td>0.038880</td>\n",
       "      <td>0.170122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151727</td>\n",
       "      <td>0.175623</td>\n",
       "      <td>0.258102</td>\n",
       "      <td>0.078604</td>\n",
       "      <td>-0.023349</td>\n",
       "      <td>-0.069403</td>\n",
       "      <td>-0.019248</td>\n",
       "      <td>0.273587</td>\n",
       "      <td>0.323913</td>\n",
       "      <td>0.156899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.600053</td>\n",
       "      <td>0.450454</td>\n",
       "      <td>0.407950</td>\n",
       "      <td>0.554324</td>\n",
       "      <td>0.457576</td>\n",
       "      <td>0.747958</td>\n",
       "      <td>0.101570</td>\n",
       "      <td>-0.024283</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.244049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570132</td>\n",
       "      <td>0.192315</td>\n",
       "      <td>-0.015206</td>\n",
       "      <td>0.073420</td>\n",
       "      <td>0.150168</td>\n",
       "      <td>-0.086901</td>\n",
       "      <td>0.118768</td>\n",
       "      <td>0.432538</td>\n",
       "      <td>0.563580</td>\n",
       "      <td>0.360348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.427308</td>\n",
       "      <td>0.239172</td>\n",
       "      <td>0.101873</td>\n",
       "      <td>0.266489</td>\n",
       "      <td>0.325015</td>\n",
       "      <td>0.580501</td>\n",
       "      <td>0.027387</td>\n",
       "      <td>-0.153969</td>\n",
       "      <td>0.092569</td>\n",
       "      <td>-0.007205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328638</td>\n",
       "      <td>0.170549</td>\n",
       "      <td>-0.081796</td>\n",
       "      <td>0.289600</td>\n",
       "      <td>0.185260</td>\n",
       "      <td>0.197285</td>\n",
       "      <td>0.071489</td>\n",
       "      <td>0.085987</td>\n",
       "      <td>0.124079</td>\n",
       "      <td>0.504530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.664985</td>\n",
       "      <td>0.299166</td>\n",
       "      <td>0.073119</td>\n",
       "      <td>0.407197</td>\n",
       "      <td>0.240695</td>\n",
       "      <td>0.669216</td>\n",
       "      <td>0.168402</td>\n",
       "      <td>0.111856</td>\n",
       "      <td>0.097451</td>\n",
       "      <td>0.082961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.581309</td>\n",
       "      <td>0.048278</td>\n",
       "      <td>-0.142375</td>\n",
       "      <td>0.048878</td>\n",
       "      <td>0.311628</td>\n",
       "      <td>0.185092</td>\n",
       "      <td>0.333022</td>\n",
       "      <td>0.338988</td>\n",
       "      <td>0.568694</td>\n",
       "      <td>0.423569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.774156</td>\n",
       "      <td>0.692993</td>\n",
       "      <td>0.657802</td>\n",
       "      <td>0.638374</td>\n",
       "      <td>0.702986</td>\n",
       "      <td>0.815171</td>\n",
       "      <td>0.458623</td>\n",
       "      <td>0.399123</td>\n",
       "      <td>0.261620</td>\n",
       "      <td>0.265287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105364</td>\n",
       "      <td>0.120019</td>\n",
       "      <td>-0.277395</td>\n",
       "      <td>-0.078877</td>\n",
       "      <td>0.336482</td>\n",
       "      <td>0.198354</td>\n",
       "      <td>0.335830</td>\n",
       "      <td>0.333324</td>\n",
       "      <td>0.323221</td>\n",
       "      <td>0.245797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.638093</td>\n",
       "      <td>0.324276</td>\n",
       "      <td>0.187139</td>\n",
       "      <td>0.352075</td>\n",
       "      <td>0.411690</td>\n",
       "      <td>0.353193</td>\n",
       "      <td>0.241433</td>\n",
       "      <td>0.316128</td>\n",
       "      <td>0.125938</td>\n",
       "      <td>0.223150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405868</td>\n",
       "      <td>-0.193584</td>\n",
       "      <td>-0.358174</td>\n",
       "      <td>0.548469</td>\n",
       "      <td>0.329123</td>\n",
       "      <td>0.301622</td>\n",
       "      <td>0.417169</td>\n",
       "      <td>0.293198</td>\n",
       "      <td>0.532769</td>\n",
       "      <td>0.347501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.787778</td>\n",
       "      <td>0.418824</td>\n",
       "      <td>0.420073</td>\n",
       "      <td>0.536880</td>\n",
       "      <td>0.531874</td>\n",
       "      <td>0.776564</td>\n",
       "      <td>0.222002</td>\n",
       "      <td>0.235727</td>\n",
       "      <td>-0.130599</td>\n",
       "      <td>0.042551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268867</td>\n",
       "      <td>0.526304</td>\n",
       "      <td>0.287224</td>\n",
       "      <td>0.044076</td>\n",
       "      <td>-0.042164</td>\n",
       "      <td>-0.138347</td>\n",
       "      <td>0.116347</td>\n",
       "      <td>-0.128351</td>\n",
       "      <td>-0.010187</td>\n",
       "      <td>0.564968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.837095</td>\n",
       "      <td>0.699350</td>\n",
       "      <td>0.567253</td>\n",
       "      <td>0.628090</td>\n",
       "      <td>0.484317</td>\n",
       "      <td>0.816644</td>\n",
       "      <td>0.515332</td>\n",
       "      <td>0.440825</td>\n",
       "      <td>0.597178</td>\n",
       "      <td>0.574797</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085986</td>\n",
       "      <td>-0.333526</td>\n",
       "      <td>0.013771</td>\n",
       "      <td>-0.297782</td>\n",
       "      <td>0.018670</td>\n",
       "      <td>-0.199247</td>\n",
       "      <td>0.221397</td>\n",
       "      <td>-0.145123</td>\n",
       "      <td>0.218707</td>\n",
       "      <td>-0.338076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.626127</td>\n",
       "      <td>0.367332</td>\n",
       "      <td>0.178448</td>\n",
       "      <td>0.252641</td>\n",
       "      <td>0.384334</td>\n",
       "      <td>0.654329</td>\n",
       "      <td>0.114585</td>\n",
       "      <td>0.223127</td>\n",
       "      <td>-0.013945</td>\n",
       "      <td>0.164300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.544587</td>\n",
       "      <td>0.483774</td>\n",
       "      <td>0.286602</td>\n",
       "      <td>0.362241</td>\n",
       "      <td>0.263336</td>\n",
       "      <td>0.268425</td>\n",
       "      <td>0.312150</td>\n",
       "      <td>0.147089</td>\n",
       "      <td>0.466238</td>\n",
       "      <td>0.586675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.557446</td>\n",
       "      <td>0.129209</td>\n",
       "      <td>0.156019</td>\n",
       "      <td>0.203429</td>\n",
       "      <td>0.227152</td>\n",
       "      <td>0.392719</td>\n",
       "      <td>-0.016883</td>\n",
       "      <td>0.001975</td>\n",
       "      <td>0.058075</td>\n",
       "      <td>0.134549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337274</td>\n",
       "      <td>-0.019307</td>\n",
       "      <td>0.073617</td>\n",
       "      <td>0.149316</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.215443</td>\n",
       "      <td>0.254942</td>\n",
       "      <td>0.365357</td>\n",
       "      <td>0.477884</td>\n",
       "      <td>0.403335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows Ã— 6670 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     (Precentral_R, Precentral_L)  (Frontal_Sup_L, Precentral_L)  \\\n",
       "0                        0.590307                       0.215914   \n",
       "1                        0.600053                       0.450454   \n",
       "4                        0.427308                       0.239172   \n",
       "5                        0.664985                       0.299166   \n",
       "8                        0.774156                       0.692993   \n",
       "..                            ...                            ...   \n",
       "154                      0.638093                       0.324276   \n",
       "157                      0.787778                       0.418824   \n",
       "158                      0.837095                       0.699350   \n",
       "159                      0.626127                       0.367332   \n",
       "162                      0.557446                       0.129209   \n",
       "\n",
       "     (Frontal_Sup_L, Precentral_R)  (Frontal_Sup_R, Precentral_L)  \\\n",
       "0                         0.304414                       0.116425   \n",
       "1                         0.407950                       0.554324   \n",
       "4                         0.101873                       0.266489   \n",
       "5                         0.073119                       0.407197   \n",
       "8                         0.657802                       0.638374   \n",
       "..                             ...                            ...   \n",
       "154                       0.187139                       0.352075   \n",
       "157                       0.420073                       0.536880   \n",
       "158                       0.567253                       0.628090   \n",
       "159                       0.178448                       0.252641   \n",
       "162                       0.156019                       0.203429   \n",
       "\n",
       "     (Frontal_Sup_R, Precentral_R)  (Frontal_Sup_R, Frontal_Sup_L)  \\\n",
       "0                         0.165778                        0.255798   \n",
       "1                         0.457576                        0.747958   \n",
       "4                         0.325015                        0.580501   \n",
       "5                         0.240695                        0.669216   \n",
       "8                         0.702986                        0.815171   \n",
       "..                             ...                             ...   \n",
       "154                       0.411690                        0.353193   \n",
       "157                       0.531874                        0.776564   \n",
       "158                       0.484317                        0.816644   \n",
       "159                       0.384334                        0.654329   \n",
       "162                       0.227152                        0.392719   \n",
       "\n",
       "     (Frontal_Sup_Orb_L, Precentral_L)  (Frontal_Sup_Orb_L, Precentral_R)  \\\n",
       "0                             0.031173                          -0.113507   \n",
       "1                             0.101570                          -0.024283   \n",
       "4                             0.027387                          -0.153969   \n",
       "5                             0.168402                           0.111856   \n",
       "8                             0.458623                           0.399123   \n",
       "..                                 ...                                ...   \n",
       "154                           0.241433                           0.316128   \n",
       "157                           0.222002                           0.235727   \n",
       "158                           0.515332                           0.440825   \n",
       "159                           0.114585                           0.223127   \n",
       "162                          -0.016883                           0.001975   \n",
       "\n",
       "     (Frontal_Sup_Orb_L, Frontal_Sup_L)  (Frontal_Sup_Orb_L, Frontal_Sup_R)  \\\n",
       "0                              0.038880                            0.170122   \n",
       "1                              0.218750                            0.244049   \n",
       "4                              0.092569                           -0.007205   \n",
       "5                              0.097451                            0.082961   \n",
       "8                              0.261620                            0.265287   \n",
       "..                                  ...                                 ...   \n",
       "154                            0.125938                            0.223150   \n",
       "157                           -0.130599                            0.042551   \n",
       "158                            0.597178                            0.574797   \n",
       "159                           -0.013945                            0.164300   \n",
       "162                            0.058075                            0.134549   \n",
       "\n",
       "     ...  (Vermis_10, Cerebelum_9_R)  (Vermis_10, Cerebelum_10_L)  \\\n",
       "0    ...                    0.151727                     0.175623   \n",
       "1    ...                    0.570132                     0.192315   \n",
       "4    ...                    0.328638                     0.170549   \n",
       "5    ...                    0.581309                     0.048278   \n",
       "8    ...                    0.105364                     0.120019   \n",
       "..   ...                         ...                          ...   \n",
       "154  ...                    0.405868                    -0.193584   \n",
       "157  ...                    0.268867                     0.526304   \n",
       "158  ...                   -0.085986                    -0.333526   \n",
       "159  ...                    0.544587                     0.483774   \n",
       "162  ...                    0.337274                    -0.019307   \n",
       "\n",
       "     (Vermis_10, Cerebelum_10_R)  (Vermis_10, Vermis_1_2)  \\\n",
       "0                       0.258102                 0.078604   \n",
       "1                      -0.015206                 0.073420   \n",
       "4                      -0.081796                 0.289600   \n",
       "5                      -0.142375                 0.048878   \n",
       "8                      -0.277395                -0.078877   \n",
       "..                           ...                      ...   \n",
       "154                    -0.358174                 0.548469   \n",
       "157                     0.287224                 0.044076   \n",
       "158                     0.013771                -0.297782   \n",
       "159                     0.286602                 0.362241   \n",
       "162                     0.073617                 0.149316   \n",
       "\n",
       "     (Vermis_10, Vermis_3)  (Vermis_10, Vermis_4_5)  (Vermis_10, Vermis_6)  \\\n",
       "0                -0.023349                -0.069403              -0.019248   \n",
       "1                 0.150168                -0.086901               0.118768   \n",
       "4                 0.185260                 0.197285               0.071489   \n",
       "5                 0.311628                 0.185092               0.333022   \n",
       "8                 0.336482                 0.198354               0.335830   \n",
       "..                     ...                      ...                    ...   \n",
       "154               0.329123                 0.301622               0.417169   \n",
       "157              -0.042164                -0.138347               0.116347   \n",
       "158               0.018670                -0.199247               0.221397   \n",
       "159               0.263336                 0.268425               0.312150   \n",
       "162               0.353535                 0.215443               0.254942   \n",
       "\n",
       "     (Vermis_10, Vermis_7)  (Vermis_10, Vermis_8)  (Vermis_10, Vermis_9)  \n",
       "0                 0.273587               0.323913               0.156899  \n",
       "1                 0.432538               0.563580               0.360348  \n",
       "4                 0.085987               0.124079               0.504530  \n",
       "5                 0.338988               0.568694               0.423569  \n",
       "8                 0.333324               0.323221               0.245797  \n",
       "..                     ...                    ...                    ...  \n",
       "154               0.293198               0.532769               0.347501  \n",
       "157              -0.128351              -0.010187               0.564968  \n",
       "158              -0.145123               0.218707              -0.338076  \n",
       "159               0.147089               0.466238               0.586675  \n",
       "162               0.365357               0.477884               0.403335  \n",
       "\n",
       "[80 rows x 6670 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b6cef644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "4      1\n",
       "5      1\n",
       "8      1\n",
       "      ..\n",
       "154    0\n",
       "157    1\n",
       "158    0\n",
       "159    1\n",
       "162    1\n",
       "Name: Dx, Length: 80, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "272c6bcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': 'balanced', 'penalty': 'l1', 'C': 0.01, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l1', 'C': 0.01, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l1', 'C': 0.01, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l1', 'C': 0.01, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l1', 'C': 0.01, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l1', 'C': 0.1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l1', 'C': 0.1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l1', 'C': 0.1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l1', 'C': 0.1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l1', 'C': 0.1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l1', 'C': 1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l1', 'C': 1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l1', 'C': 1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l1', 'C': 1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l1', 'C': 1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l1', 'C': 3, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l1', 'C': 3, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l1', 'C': 3, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l1', 'C': 3, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l1', 'C': 3, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l1', 'C': 10, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l1', 'C': 10, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l1', 'C': 10, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l1', 'C': 10, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l1', 'C': 10, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l2', 'C': 0.01, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l2', 'C': 0.01, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l2', 'C': 0.01, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l2', 'C': 0.01, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l2', 'C': 0.01, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l2', 'C': 0.1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l2', 'C': 0.1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l2', 'C': 0.1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l2', 'C': 0.1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l2', 'C': 0.1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l2', 'C': 1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l2', 'C': 1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l2', 'C': 1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l2', 'C': 1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l2', 'C': 1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l2', 'C': 3, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l2', 'C': 3, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l2', 'C': 3, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l2', 'C': 3, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l2', 'C': 3, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l2', 'C': 10, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l2', 'C': 10, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l2', 'C': 10, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l2', 'C': 10, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': 'balanced', 'penalty': 'l2', 'C': 10, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l1', 'C': 0.01, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l1', 'C': 0.01, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l1', 'C': 0.01, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l1', 'C': 0.01, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l1', 'C': 0.01, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l1', 'C': 0.1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l1', 'C': 0.1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l1', 'C': 0.1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l1', 'C': 0.1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l1', 'C': 0.1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l1', 'C': 1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l1', 'C': 1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l1', 'C': 1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l1', 'C': 1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l1', 'C': 1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l1', 'C': 3, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l1', 'C': 3, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l1', 'C': 3, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l1', 'C': 3, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l1', 'C': 3, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l1', 'C': 10, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l1', 'C': 10, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l1', 'C': 10, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l1', 'C': 10, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l1', 'C': 10, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l2', 'C': 0.01, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l2', 'C': 0.01, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l2', 'C': 0.01, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l2', 'C': 0.01, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l2', 'C': 0.01, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l2', 'C': 0.1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l2', 'C': 0.1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l2', 'C': 0.1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l2', 'C': 0.1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l2', 'C': 0.1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l2', 'C': 1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l2', 'C': 1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l2', 'C': 1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l2', 'C': 1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l2', 'C': 1, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l2', 'C': 3, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l2', 'C': 3, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l2', 'C': 3, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l2', 'C': 3, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l2', 'C': 3, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l2', 'C': 10, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l2', 'C': 10, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l2', 'C': 10, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l2', 'C': 10, 'solver': 'liblinear', 'random_state': 1380}\n",
      "{'class_weight': None, 'penalty': 'l2', 'C': 10, 'solver': 'liblinear', 'random_state': 1380}\n"
     ]
    }
   ],
   "source": [
    "results =[]\n",
    "for hyperparameter in hyperparameter_combinations:\n",
    "    record,f1_metrics, accs ={}, [], []\n",
    "    record['hyperparameter'] =hyperparameter\n",
    "    for i, split in enumerate(data_json['train']):\n",
    "        X_train, y_train, X_val, y_val =splits_data(dataset, split)\n",
    "        print(hyperparameter)\n",
    "        lr =LogisticRegression(**hyperparameter)\n",
    "        lr.fit(X_train,y_train)\n",
    "        predicted_val =lr.predict(X_val)\n",
    "        f1_metric =f1_score(y_val,predicted_val)\n",
    "        f1_metrics.append(f1_metric)\n",
    "\n",
    "    record['f1_mean'] =  np.mean(f1_metrics) \n",
    "    record['f1_std'] =  np.std(f1_metrics) \n",
    "    results.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "56fe679b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hyperparameter    {'class_weight': None, 'penalty': 'l2', 'C': 0...\n",
       "f1_mean                                                    0.668046\n",
       "f1_std                                                     0.213694\n",
       "Name: 19, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_records(results).sort_values(by =\"f1_mean\").reset_index(drop=True).iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f02118a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params =pd.DataFrame.from_records(results).sort_values(by =\"f1_mean\").reset_index(drop=True).iloc[-1]['hyperparameter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "41363cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': None,\n",
       " 'penalty': 'l2',\n",
       " 'C': 0.1,\n",
       " 'solver': 'liblinear',\n",
       " 'random_state': 1380}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "56faa686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666667 0.6923076923076923 0.696969696969697\n",
      "0.6666666666666666 0.7307692307692307 0.7181818181818181\n",
      "0.7826086956521738 0.8076923076923077 0.8090909090909092\n",
      "0.8 0.8076923076923077 0.8212121212121213\n",
      "0.7272727272727273 0.7692307692307693 0.7636363636363637\n"
     ]
    }
   ],
   "source": [
    "f1_metrics, roc_aucs, accs=[], [], []\n",
    "for i, split in enumerate(data_json['train']):\n",
    "    train_ids,val_ids, test_ids =split['train'],split['valid'], data_json['test']\n",
    "\n",
    "    train_data =dataset.loc[dataset.Subjectid.isin(train_ids)]\n",
    "    test_data =dataset.loc[dataset.Subjectid.isin(test_ids)]\n",
    "    X_train, y_train =train_data.iloc[:,:-2], train_data.iloc[:,-1]\n",
    "    X_test, y_test =test_data.iloc[:,:-2], test_data.iloc[:,-1]\n",
    "    lr =LogisticRegression(**best_params)\n",
    "    lr.fit(X_train,y_train)\n",
    "    predicted_test =lr.predict(X_test)\n",
    "    f1_metric =f1_score(y_test,predicted_test)\n",
    "    acc_metric =accuracy_score(y_test,predicted_test)\n",
    "    roc_auc =roc_auc_score(y_test,predicted_test)\n",
    "    print(f1_metric ,acc_metric, roc_auc)\n",
    "    f1_metrics.append(f1_metric)\n",
    "    roc_aucs.append(roc_auc)\n",
    "    accs.append(acc_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "360cc860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.728642951251647"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(f1_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "94221ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05601451096001315"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(f1_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e1d0bc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7615384615384615"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fcadf4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.044853476114194636"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "398d0a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7618181818181818"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(roc_aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a87d5a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04873420725569609"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(roc_aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dfa6565f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7826086956521738 0.8076923076923077 0.8090909090909092\n",
      "0.7826086956521738 0.8076923076923077 0.8090909090909092\n",
      "0.7826086956521738 0.8076923076923077 0.8090909090909092\n",
      "0.7826086956521738 0.8076923076923077 0.8090909090909092\n",
      "0.7826086956521738 0.8076923076923077 0.8090909090909092\n"
     ]
    }
   ],
   "source": [
    "f1_metrics, roc_aucs, accs=[], [], []\n",
    "for i, split in enumerate(data_json['train']):\n",
    "    train_ids,val_ids, test_ids =split['train'],split['valid'], data_json['test']\n",
    "\n",
    "    train_data =dataset.loc[dataset.Subjectid.isin(train_ids+val_ids)]\n",
    "    test_data =dataset.loc[dataset.Subjectid.isin(test_ids)]\n",
    "    X_train, y_train =train_data.iloc[:,:-2], train_data.iloc[:,-1]\n",
    "    X_test, y_test =test_data.iloc[:,:-2], test_data.iloc[:,-1]\n",
    "    lr =LogisticRegression(**best_params)\n",
    "    lr.fit(X_train,y_train)\n",
    "    predicted_test =lr.predict(X_test)\n",
    "    f1_metric =f1_score(y_test,predicted_test)\n",
    "    acc_metric =accuracy_score(y_test,predicted_test)\n",
    "    roc_auc =roc_auc_score(y_test,predicted_test)\n",
    "    print(f1_metric ,acc_metric, roc_auc)\n",
    "    f1_metrics.append(f1_metric)\n",
    "    roc_aucs.append(roc_auc)\n",
    "    accs.append(acc_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51f4dd8",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f27361f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'n_estimators': [10, 50, 100],\n",
    "                   'max_depth':  [3,5,7,9],\n",
    "                   'class_weight': [None],\n",
    "                   'random_state': [seed]\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5038d3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys, values = zip(*hyperparameters.items())\n",
    "hyperparameter_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "95ee70d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splits_data(dataset, split):\n",
    "    train_ids, valid_ids =split['train'],split['valid']\n",
    "\n",
    "    train_data =dataset.loc[dataset.Subjectid.isin(train_ids)]\n",
    "    val_data =dataset.loc[dataset.Subjectid.isin(valid_ids)]\n",
    "    X_train, y_train =train_data.iloc[:,:-2], train_data.iloc[:,-1]\n",
    "    X_val, y_val =val_data.iloc[:,:-2], val_data.iloc[:,-1]\n",
    "    return X_train, y_train, X_val, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bd37cc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 10, 'max_depth': 3, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 10, 'max_depth': 3, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 10, 'max_depth': 3, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 10, 'max_depth': 3, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 10, 'max_depth': 3, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 10, 'max_depth': 5, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 10, 'max_depth': 5, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 10, 'max_depth': 5, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 10, 'max_depth': 5, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 10, 'max_depth': 5, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 10, 'max_depth': 7, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 10, 'max_depth': 7, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 10, 'max_depth': 7, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 10, 'max_depth': 7, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 10, 'max_depth': 7, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 10, 'max_depth': 9, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 10, 'max_depth': 9, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 10, 'max_depth': 9, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 10, 'max_depth': 9, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 10, 'max_depth': 9, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 50, 'max_depth': 3, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 50, 'max_depth': 3, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 50, 'max_depth': 3, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 50, 'max_depth': 3, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 50, 'max_depth': 3, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 50, 'max_depth': 5, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 50, 'max_depth': 5, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 50, 'max_depth': 5, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 50, 'max_depth': 5, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 50, 'max_depth': 5, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 50, 'max_depth': 7, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 50, 'max_depth': 7, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 50, 'max_depth': 7, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 50, 'max_depth': 7, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 50, 'max_depth': 7, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 50, 'max_depth': 9, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 50, 'max_depth': 9, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 50, 'max_depth': 9, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 50, 'max_depth': 9, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 50, 'max_depth': 9, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 100, 'max_depth': 3, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 100, 'max_depth': 3, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 100, 'max_depth': 3, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 100, 'max_depth': 3, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 100, 'max_depth': 3, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 100, 'max_depth': 5, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 100, 'max_depth': 5, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 100, 'max_depth': 5, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 100, 'max_depth': 5, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 100, 'max_depth': 5, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 100, 'max_depth': 7, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 100, 'max_depth': 7, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 100, 'max_depth': 7, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 100, 'max_depth': 7, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 100, 'max_depth': 7, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 100, 'max_depth': 9, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 100, 'max_depth': 9, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 100, 'max_depth': 9, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 100, 'max_depth': 9, 'class_weight': None, 'random_state': 1380}\n",
      "{'n_estimators': 100, 'max_depth': 9, 'class_weight': None, 'random_state': 1380}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def splits_data(dataset, split):\n",
    "    train_ids, valid_ids =split['train'],split['valid']\n",
    "\n",
    "    train_data =dataset.loc[dataset.Subjectid.isin(train_ids)]\n",
    "    val_data =dataset.loc[dataset.Subjectid.isin(valid_ids)]\n",
    "    X_train, y_train =train_data.iloc[:,:-2], train_data.iloc[:,-1]\n",
    "    X_val, y_val =val_data.iloc[:,:-2], val_data.iloc[:,-1]\n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "results = []\n",
    "for hyperparameter in hyperparameter_combinations:\n",
    "    record, f1_metrics, accs = {}, [], []\n",
    "    record['hyperparameter'] = hyperparameter\n",
    "    for i, split in enumerate(data_json['train']):\n",
    "        X_train, y_train, X_val, y_val = splits_data(dataset, split)\n",
    "        print(hyperparameter)\n",
    "        rf = RandomForestClassifier(**hyperparameter)\n",
    "        rf.fit(X_train, y_train)\n",
    "        predicted_val = rf.predict(X_val)\n",
    "        f1_metric = f1_score(y_val, predicted_val)\n",
    "        f1_metrics.append(f1_metric)\n",
    "\n",
    "    record['f1_mean'] = np.mean(f1_metrics)\n",
    "    record['f1_std'] = np.std(f1_metrics)\n",
    "    results.append(record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "749ce309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hyperparameter    {'n_estimators': 50, 'max_depth': 3, 'class_we...\n",
       "f1_mean                                                    0.615171\n",
       "f1_std                                                     0.166889\n",
       "Name: 11, dtype: object"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_records(results).sort_values(by =\"f1_mean\").reset_index(drop=True).iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "eab582e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params =pd.DataFrame.from_records(results).sort_values(by =\"f1_mean\").reset_index(drop=True).iloc[-1]['hyperparameter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b12e298c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 50,\n",
       " 'max_depth': 3,\n",
       " 'class_weight': None,\n",
       " 'random_state': 1380}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ee11d103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6086956521739131 0.6538461538461539 0.6515151515151516\n",
      "0.6 0.6923076923076923 0.6727272727272727\n",
      "0.7826086956521738 0.8076923076923077 0.8090909090909092\n",
      "0.6666666666666667 0.6923076923076923 0.696969696969697\n",
      "0.5833333333333334 0.6153846153846154 0.6181818181818182\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
    "\n",
    "f1_metrics, roc_aucs, accs = [], [], []\n",
    "\n",
    "for i, split in enumerate(data_json['train']):\n",
    "    train_ids, val_ids, test_ids = split['train'], split['valid'], data_json['test']\n",
    "\n",
    "    train_data = dataset.loc[dataset.Subjectid.isin(train_ids)]\n",
    "    test_data = dataset.loc[dataset.Subjectid.isin(test_ids)]\n",
    "    X_train, y_train = train_data.iloc[:, :-2], train_data.iloc[:, -1]\n",
    "    X_test, y_test = test_data.iloc[:, :-2], test_data.iloc[:, -1]\n",
    "\n",
    "    # Initialize the random forest classifier with best hyperparameters\n",
    "    rf = RandomForestClassifier(n_estimators=50, max_depth=3, class_weight = None, random_state = 1380)\n",
    "    rf.fit(X_train, y_train)\n",
    "    predicted_test = rf.predict(X_test)\n",
    "\n",
    "    f1_metric = f1_score(y_test, predicted_test)\n",
    "    acc_metric = accuracy_score(y_test, predicted_test)\n",
    "    roc_auc = roc_auc_score(y_test, predicted_test)\n",
    "    \n",
    "    print(f1_metric, acc_metric, roc_auc)\n",
    "    \n",
    "    f1_metrics.append(f1_metric)\n",
    "    roc_aucs.append(roc_auc)\n",
    "    accs.append(acc_metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6911ebed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6482608695652174"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(f1_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2dc20ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07279864649948585"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(f1_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "70c0bf30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6923076923076924"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c527acc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06435846357954426"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "140f4046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6896969696969697"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(roc_aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f1867bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06506618795831673"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(roc_aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b7f85313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.6153846153846154 0.593939393939394\n",
      "0.5 0.6153846153846154 0.593939393939394\n",
      "0.5 0.6153846153846154 0.593939393939394\n",
      "0.5 0.6153846153846154 0.593939393939394\n",
      "0.5 0.6153846153846154 0.593939393939394\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
    "\n",
    "f1_metrics, roc_aucs, accs = [], [], []\n",
    "\n",
    "for i, split in enumerate(data_json['train']):\n",
    "    train_ids, val_ids, test_ids = split['train'], split['valid'], data_json['test']\n",
    "\n",
    "    train_data = dataset.loc[dataset.Subjectid.isin(train_ids + val_ids)]\n",
    "    test_data = dataset.loc[dataset.Subjectid.isin(test_ids)]\n",
    "    X_train, y_train = train_data.iloc[:,:-2], train_data.iloc[:,-1]\n",
    "    X_test, y_test = test_data.iloc[:,:-2], test_data.iloc[:,-1]\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=50, max_depth=3, class_weight = None, random_state = 1380) # specify the number of trees in the forest\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    predicted_test = rf.predict(X_test)\n",
    "    f1_metric = f1_score(y_test, predicted_test)\n",
    "    acc_metric = accuracy_score(y_test, predicted_test)\n",
    "    roc_auc = roc_auc_score(y_test, predicted_test)\n",
    "    \n",
    "    print(f1_metric, acc_metric, roc_auc)\n",
    "    f1_metrics.append(f1_metric)\n",
    "    roc_aucs.append(roc_auc)\n",
    "    accs.append(acc_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e894af18",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "22922715",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "00adc5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'C': [0.01, 0.1, 1, 10],\n",
    "                   'kernel': ['linear', 'rbf'],\n",
    "                   'class_weight': [\"balanced\", None],\n",
    "                   'probability': [True],\n",
    "                   'random_state': [seed]\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bf2f5294",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys, values = zip(*hyperparameters.items())\n",
    "hyperparameter_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f47bbb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splits_data(dataset, split):\n",
    "    train_ids, valid_ids =split['train'],split['valid']\n",
    "\n",
    "    train_data =dataset.loc[dataset.Subjectid.isin(train_ids)]\n",
    "    val_data =dataset.loc[dataset.Subjectid.isin(valid_ids)]\n",
    "    X_train, y_train =train_data.iloc[:,:-2], train_data.iloc[:,-1]\n",
    "    X_val, y_val =val_data.iloc[:,:-2], val_data.iloc[:,-1]\n",
    "    return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9e29a89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'kernel': 'linear', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.01, 'kernel': 'linear', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.01, 'kernel': 'linear', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.01, 'kernel': 'linear', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.01, 'kernel': 'linear', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.01, 'kernel': 'linear', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.01, 'kernel': 'linear', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.01, 'kernel': 'linear', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.01, 'kernel': 'linear', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.01, 'kernel': 'linear', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.01, 'kernel': 'rbf', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.01, 'kernel': 'rbf', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.01, 'kernel': 'rbf', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.01, 'kernel': 'rbf', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.01, 'kernel': 'rbf', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.01, 'kernel': 'rbf', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.01, 'kernel': 'rbf', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.01, 'kernel': 'rbf', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.01, 'kernel': 'rbf', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.01, 'kernel': 'rbf', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.1, 'kernel': 'linear', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.1, 'kernel': 'linear', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.1, 'kernel': 'linear', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.1, 'kernel': 'linear', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.1, 'kernel': 'linear', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.1, 'kernel': 'linear', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.1, 'kernel': 'linear', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.1, 'kernel': 'linear', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.1, 'kernel': 'linear', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.1, 'kernel': 'linear', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.1, 'kernel': 'rbf', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.1, 'kernel': 'rbf', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.1, 'kernel': 'rbf', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.1, 'kernel': 'rbf', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.1, 'kernel': 'rbf', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.1, 'kernel': 'rbf', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.1, 'kernel': 'rbf', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.1, 'kernel': 'rbf', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.1, 'kernel': 'rbf', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 0.1, 'kernel': 'rbf', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 1, 'kernel': 'linear', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 1, 'kernel': 'linear', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 1, 'kernel': 'linear', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 1, 'kernel': 'linear', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 1, 'kernel': 'linear', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 1, 'kernel': 'linear', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 1, 'kernel': 'linear', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 1, 'kernel': 'linear', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 1, 'kernel': 'linear', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 1, 'kernel': 'linear', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 1, 'kernel': 'rbf', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 1, 'kernel': 'rbf', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 1, 'kernel': 'rbf', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 1, 'kernel': 'rbf', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 1, 'kernel': 'rbf', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 1, 'kernel': 'rbf', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 1, 'kernel': 'rbf', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 1, 'kernel': 'rbf', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 1, 'kernel': 'rbf', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 1, 'kernel': 'rbf', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 10, 'kernel': 'linear', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 10, 'kernel': 'linear', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 10, 'kernel': 'linear', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 10, 'kernel': 'linear', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 10, 'kernel': 'linear', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 10, 'kernel': 'linear', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 10, 'kernel': 'linear', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 10, 'kernel': 'linear', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 10, 'kernel': 'linear', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 10, 'kernel': 'linear', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 10, 'kernel': 'rbf', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 10, 'kernel': 'rbf', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 10, 'kernel': 'rbf', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 10, 'kernel': 'rbf', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 10, 'kernel': 'rbf', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n",
      "{'C': 10, 'kernel': 'rbf', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 10, 'kernel': 'rbf', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 10, 'kernel': 'rbf', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 10, 'kernel': 'rbf', 'class_weight': None, 'probability': True, 'random_state': 1380}\n",
      "{'C': 10, 'kernel': 'rbf', 'class_weight': None, 'probability': True, 'random_state': 1380}\n"
     ]
    }
   ],
   "source": [
    "def splits_data(dataset, split):\n",
    "    train_ids, valid_ids = split['train'], split['valid']\n",
    "\n",
    "    train_data = dataset.loc[dataset.Subjectid.isin(train_ids)]\n",
    "    val_data = dataset.loc[dataset.Subjectid.isin(valid_ids)]\n",
    "    X_train, y_train = train_data.iloc[:,:-2], train_data.iloc[:,-1]\n",
    "    X_val, y_val = val_data.iloc[:,:-2], val_data.iloc[:,-1]\n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "results = []\n",
    "for hyperparameter in hyperparameter_combinations:\n",
    "    record, f1_metrics, accs = {}, [], []\n",
    "    record['hyperparameter'] = hyperparameter\n",
    "    for i, split in enumerate(data_json['train']):\n",
    "        X_train, y_train, X_val, y_val = splits_data(dataset, split)\n",
    "        print(hyperparameter)\n",
    "        svm = SVC(**hyperparameter)\n",
    "        svm.fit(X_train, y_train)\n",
    "        predicted_val = svm.predict(X_val)\n",
    "        f1_metric = f1_score(y_val, predicted_val)\n",
    "        f1_metrics.append(f1_metric)\n",
    "\n",
    "    record['f1_mean'] = np.mean(f1_metrics)\n",
    "    record['f1_std'] = np.std(f1_metrics)\n",
    "    results.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0461c76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hyperparameter    {'C': 0.01, 'kernel': 'linear', 'class_weight'...\n",
       "f1_mean                                                     0.67405\n",
       "f1_std                                                     0.216906\n",
       "Name: 15, dtype: object"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_records(results).sort_values(by =\"f1_mean\").reset_index(drop=True).iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a5df3947",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params =pd.DataFrame.from_records(results).sort_values(by =\"f1_mean\").reset_index(drop=True).iloc[-1]['hyperparameter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9fac78b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.01,\n",
       " 'kernel': 'linear',\n",
       " 'class_weight': None,\n",
       " 'probability': True,\n",
       " 'random_state': 1380}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2affda31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7500000000000001 0.7692307692307693 0.7757575757575759\n",
      "0.6666666666666666 0.7307692307692307 0.7181818181818181\n",
      "0.8333333333333333 0.8461538461538461 0.8545454545454546\n",
      "0.8 0.8076923076923077 0.8212121212121213\n",
      "0.7272727272727273 0.7692307692307693 0.7636363636363637\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
    "\n",
    "f1_metrics, roc_aucs, accs = [], [], []\n",
    "\n",
    "for i, split in enumerate(data_json['train']):\n",
    "    train_ids, val_ids, test_ids = split['train'], split['valid'], data_json['test']\n",
    "\n",
    "    train_data = dataset.loc[dataset.Subjectid.isin(train_ids)]\n",
    "    test_data = dataset.loc[dataset.Subjectid.isin(test_ids)]\n",
    "    X_train, y_train = train_data.iloc[:, :-2], train_data.iloc[:, -1]\n",
    "    X_test, y_test = test_data.iloc[:, :-2], test_data.iloc[:, -1]\n",
    "\n",
    "    # Initialize the SVM classifier with best hyperparameters\n",
    "    svm = SVC(C=0.1, kernel='linear', class_weight='balanced', probability=True, random_state=1380)\n",
    "    svm.fit(X_train, y_train)\n",
    "    predicted_test = svm.predict(X_test)\n",
    "\n",
    "    f1_metric = f1_score(y_test, predicted_test)\n",
    "    acc_metric = accuracy_score(y_test, predicted_test)\n",
    "    roc_auc = roc_auc_score(y_test, predicted_test)\n",
    "    \n",
    "    print(f1_metric, acc_metric, roc_auc)\n",
    "    \n",
    "    f1_metrics.append(f1_metric)\n",
    "    roc_aucs.append(roc_auc)\n",
    "    accs.append(acc_metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "89b2e52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7554545454545455"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(f1_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cd08a156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05789068575156147"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(f1_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c318de53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7846153846153847"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1fe656cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.039223227027636816"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7b6d67dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7866666666666667"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(roc_aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2098e7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04720274540271701"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(roc_aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edff167c",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "af7dde15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac092d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'use_label_encoder': [False],\n",
    "        'objective': ['binary:logistic'],\n",
    "        'eval_metric': ['error'],\n",
    "        'eta': [0.1],\n",
    "        'max_depth':  [6,7,3,10],\n",
    "        'scale_pos_weight': [1],\n",
    "        'subsample': [1, 0.5],\n",
    "        'alpha': [0],\n",
    "        'random_state': [seed]\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29e9615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splits_data(dataset, split):\n",
    "    train_ids, valid_ids =split['train'],split['valid']\n",
    "\n",
    "    train_data =dataset.loc[dataset.Subjectid.isin(train_ids)]\n",
    "    val_data =dataset.loc[dataset.Subjectid.isin(valid_ids)]\n",
    "    X_train, y_train =train_data.iloc[:,:-2], train_data.iloc[:,-1]\n",
    "    X_val, y_val =val_data.iloc[:,:-2], val_data.iloc[:,-1]\n",
    "    return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a10c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
    "\n",
    "def splits_data(dataset, split):\n",
    "    train_ids, valid_ids = split['train'], split['valid']\n",
    "\n",
    "    train_data = dataset.loc[dataset.Subjectid.isin(train_ids)]\n",
    "    val_data = dataset.loc[dataset.Subjectid.isin(valid_ids)]\n",
    "    X_train, y_train = train_data.iloc[:,:-2], train_data.iloc[:,-1]\n",
    "    X_val, y_val = val_data.iloc[:,:-2], val_data.iloc[:,-1]\n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "results = []\n",
    "for hyperparameter in hyperparameter_combinations:\n",
    "    record, f1_metrics, accs = {}, [], []\n",
    "    record['hyperparameter'] = hyperparameter\n",
    "    for i, split in enumerate(data_json['train']):\n",
    "        X_train, y_train, X_val, y_val = splits_data(dataset, split)\n",
    "        print(hyperparameter)\n",
    "        xgb_classifier = xgb.XGBClassifier(**hyperparameter)\n",
    "        xgb_classifier.fit(X_train, y_train)\n",
    "        predicted_val = xgb_classifier.predict(X_val)\n",
    "        f1_metric = f1_score(y_val, predicted_val)\n",
    "        f1_metrics.append(f1_metric)\n",
    "\n",
    "    record['f1_mean'] = np.mean(f1_metrics)\n",
    "    record['f1_std'] = np.std(f1_metrics)\n",
    "    results.append(record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3556dab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "267343fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as ltb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5930e874",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'model__boosting_type': ['gbdt'],\n",
    "    'model__objective': ['binary'],\n",
    "    'model__n_estimators': [50],\n",
    "    'model__num_leaves': [6],\n",
    "    'model__max_depth': [3],\n",
    "    'model__learning_rate': [0.05, 0.1],\n",
    "    'model__class_weight': [None],\n",
    "    'model__min_split_gain': [0.3],\n",
    "    'model__min_child_samples': [5],\n",
    "    'model__subsample': [0.2, 0.5],\n",
    "    'model__colsample_bytree': [0.2, 0.5],\n",
    "    'model__reg_alpha': [0.0],\n",
    "    'model__reg_lambda': [0.0],\n",
    "    'model__random_state': [1380],\n",
    "    'model__n_jobs': [1],\n",
    "    'model__silent': [True],\n",
    "    'model__importance_type': ['split']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7187d37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys, values = zip(*hyperparameters.items())\n",
    "hyperparameter_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "78a17671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splits_data(dataset, split):\n",
    "    train_ids, valid_ids =split['train'],split['valid']\n",
    "\n",
    "    train_data =dataset.loc[dataset.Subjectid.isin(train_ids)]\n",
    "    val_data =dataset.loc[dataset.Subjectid.isin(valid_ids)]\n",
    "    X_train, y_train =train_data.iloc[:,:-2], train_data.iloc[:,-1]\n",
    "    X_val, y_val =val_data.iloc[:,:-2], val_data.iloc[:,-1]\n",
    "    return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c8dd5ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'kernel': 'linear', 'class_weight': 'balanced', 'probability': True, 'random_state': 1380}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lightgbm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [166]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m X_train, y_train, X_val, y_val \u001b[38;5;241m=\u001b[39m splits_data(dataset, split)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(hyperparameter)\n\u001b[1;32m---> 17\u001b[0m ltb \u001b[38;5;241m=\u001b[39m \u001b[43mlightgbm\u001b[49m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhyperparameter)\n\u001b[0;32m     18\u001b[0m ltb\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     19\u001b[0m predicted_val \u001b[38;5;241m=\u001b[39m ltb\u001b[38;5;241m.\u001b[39mpredict(X_val)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lightgbm' is not defined"
     ]
    }
   ],
   "source": [
    "def splits_data(dataset, split):\n",
    "    train_ids, valid_ids = split['train'], split['valid']\n",
    "\n",
    "    train_data = dataset.loc[dataset.Subjectid.isin(train_ids)]\n",
    "    val_data = dataset.loc[dataset.Subjectid.isin(valid_ids)]\n",
    "    X_train, y_train = train_data.iloc[:,:-2], train_data.iloc[:,-1]\n",
    "    X_val, y_val = val_data.iloc[:,:-2], val_data.iloc[:,-1]\n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "results = []\n",
    "for hyperparameter in hyperparameter_combinations:\n",
    "    record, f1_metrics, accs = {}, [], []\n",
    "    record['hyperparameter'] = hyperparameter\n",
    "    for i, split in enumerate(data_json['train']):\n",
    "        X_train, y_train, X_val, y_val = splits_data(dataset, split)\n",
    "        print(hyperparameter)\n",
    "        ltb = lightgbm(**hyperparameter)\n",
    "        ltb.fit(X_train, y_train)\n",
    "        predicted_val = ltb.predict(X_val)\n",
    "        f1_metric = f1_score(y_val, predicted_val)\n",
    "        f1_metrics.append(f1_metric)\n",
    "\n",
    "    record['f1_mean'] = np.mean(f1_metrics)\n",
    "    record['f1_std'] = np.std(f1_metrics)\n",
    "    results.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8c4ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
